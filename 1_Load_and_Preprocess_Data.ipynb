{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMFOF/sNw6z+rQWvuSNLJtB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ExE1UjHR34HE","executionInfo":{"status":"ok","timestamp":1749601551522,"user_tz":240,"elapsed":17218,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}},"outputId":"20262b4b-7ddf-443c-e0a8-e18cf8bb170c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## README\n","\n","This notebook is responsible for downloading, preprocessing, and splitting the Brain MRI dataset from Kaggle in preparation for federated learning (FL) simulations.\n","\n","It is a critical component of the reproducibility pipeline for our study Privacy-Preserving Biomedical AI in Local and Federated Learning using Gerchberg‚ÄìSaxton Data Transformations\" [link_to_publication]. Please ensure that you follow the instructions in this notebook step-by-step to maintain consistency with the experimental setup described in the manuscript.\n","\n","### ‚ö†Ô∏è Final Step Required\n","At the end of this notebook, you will be prompted to define a local saving path for the preprocessed data.\n","\n","üö® Do not skip this step.\n","\n","The saved data is required for all downstream notebooks, including Gerchberg‚ÄìSaxton transformations and federated model training."],"metadata":{"id":"054kOX2ANiW6"}},{"cell_type":"markdown","source":["## Imports and Functions\n","\n","Cells below are the definitions of some helper functions we will be using in this notebook to read/write, preprocess and save the data in our workspace.\n","\n","You can simply run all cells with no modification until the next block of cells (Load Data)."],"metadata":{"id":"XH8tlEvN72ZC"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","\n","# Read all images and corresponding labels\n","def load_images_and_labels(base_path):\n","    images = []\n","    labels = []\n","    label_map = {\"glioma\": 0, \"meningioma\": 1, \"notumor\": 2, \"pituitary\": 3}\n","\n","    for folder_type in [\"Testing\", \"Training\"]:\n","        folder_path = os.path.join(base_path, folder_type)\n","        for label_name, label_id in label_map.items():\n","            label_folder_path = os.path.join(folder_path, label_name)\n","            if os.path.exists(label_folder_path):\n","                for img_file in os.listdir(label_folder_path):\n","                    if img_file.endswith(\".jpg\"):\n","                        img_path = os.path.join(label_folder_path, img_file)\n","                        try:\n","                            img = Image.open(img_path)\n","                            images.append(img)\n","                            labels.append(label_id)\n","                        except Exception as e:\n","                            print(f\"Error loading image {img_path}: {e}\")\n","    return images, labels\n","\n","# Resize and preprocess images\n","def preprocess_images(image_list, target_size=(299, 299)):\n","    processed_images = []\n","    for img in image_list:\n","        # Resize\n","        img_resized = img.resize(target_size)\n","        # Convert to grayscale (remove channel dimension)\n","        img_gray = img_resized.convert('L')\n","        # Convert to numpy array\n","        img_array = np.array(img_gray)\n","        # Normalize (simple normalization to [0, 1])\n","        img_normalized = img_array.astype(np.float32) / 255.0\n","        processed_images.append(img_normalized)\n","\n","    return np.array(processed_images)"],"metadata":{"id":"ZG4Hz1FA7mQV","executionInfo":{"status":"ok","timestamp":1749601556747,"user_tz":240,"elapsed":2218,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Split data for clients and testing\n","def split_data_for_fl(images, labels, client_ratios, min_test_size=1000):\n","\n","    # Ensure enough data for testing\n","    if len(images) < min_test_size:\n","         raise ValueError(f\"Not enough data for minimum test size ({min_test_size})\")\n","\n","    # Split into training (clients) and testing sets\n","    train_images, test_images, train_labels, test_labels = train_test_split(\n","        images, labels, test_size=min_test_size, random_state=42, stratify=labels\n","    )\n","\n","    # Split training data among clients\n","    total_train_size = len(train_images)\n","    client_datasets = []\n","    current_start_index = 0\n","\n","    for ratio in client_ratios:\n","        client_size = int(total_train_size * ratio)\n","        client_end_index = current_start_index + client_size\n","\n","        client_images = train_images[current_start_index:client_end_index]\n","        client_labels = train_labels[current_start_index:client_end_index]\n","\n","        client_datasets.append((client_images, client_labels))\n","        current_start_index = client_end_index\n","\n","    # Add any remaining data to the last client\n","    if current_start_index < total_train_size:\n","        client_datasets[-1] = (\n","            np.concatenate((client_datasets[-1][0], train_images[current_start_index:])),\n","            np.concatenate((client_datasets[-1][1], train_labels[current_start_index:]))\n","        )\n","\n","    return client_datasets, (test_images, test_labels)"],"metadata":{"id":"XxV3nGe57mGh","executionInfo":{"status":"ok","timestamp":1749601556755,"user_tz":240,"elapsed":2,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Load and Preprocess Data\n","Below, we will be importing the data from kaggle using kagglehub.\n","Running the code below will automatically download the data to the folder path given as \"path\" variable.\n","\n","\n","Alternatively you can download the zipped data from the link below. Please make sure you save the data in your workspace for future steps.\n","\n","https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset?resource=download"],"metadata":{"id":"N0unyQif5MsY"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RslQX4co16cb","executionInfo":{"status":"ok","timestamp":1749601560641,"user_tz":240,"elapsed":3038,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}},"outputId":"c543f0ae-d6db-45b5-81e0-acbfedc631e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Path to dataset files: /kaggle/input/brain-tumor-mri-dataset\n"]}],"source":["import kagglehub\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n","\n","print(\"Path to dataset files:\", path)"]},{"cell_type":"code","source":["import gc\n","## Load data\n","# Assuming 'path' from the previous cell is the base directory for the dataset\n","# If you downloaded the zipped version from the link, please make sure the base_data_path is leading to the folder location holds Training and Testing folders.\n","base_data_path = path\n","all_images, all_labels = load_images_and_labels(base_data_path) ## Cumulate all images and labels into individual arrays\n","\n","# Preprocess data and labels\n","processed_images = preprocess_images(all_images)\n","labels_array = np.array(all_labels)\n","\n","del all_images, all_labels ## Delete unnecessary objects for memory efficiency\n","gc.collect()\n","\n","# If a channel dimension (e.g., grayscale) is required later, add:\n","# processed_images = np.expand_dims(processed_images, axis=-1)\n","\n","# Define client ratios\n","client_ratios = [0.5, 0.3, 0.2]\n","min_test_samples = 1000 # Ensure at least 1000 images for testing\n","\n","# Perform the split\n","client_data, test_data = split_data_for_fl(processed_images, labels_array, client_ratios, min_test_size=min_test_samples)\n","\n","# Print info about the resulting datasets\n","print(f\"Processed images shape: {processed_images.shape}\")\n","print(f\"Labels shape: {labels_array.shape}\")\n","\n","del processed_images, labels_array ## Delete unnecessary objects for memory efficiency\n","gc.collect()\n","\n","print(\"\\n--- Split Dataset Info ---\")\n","for i, (client_images, client_labels) in enumerate(client_data):\n","    print(f\"Client {i+1} dataset size: {len(client_images)} images\")\n","    print(f\"Client {i+1} images shape: {client_images.shape}\")\n","    print(f\"Client {i+1} labels shape: {client_labels.shape}\")\n","    print(f\"Client {i+1} label distribution: {np.unique(client_labels, return_counts = True)}\")\n","\n","print(f\"\\nTest dataset size: {len(test_data[0])} images\")\n","print(f\"Test images shape: {test_data[0].shape}\")\n","print(f\"Test labels shape: {test_data[1].shape}\")"],"metadata":{"id":"nVoBCCYT19nE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749601642613,"user_tz":240,"elapsed":81970,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}},"outputId":"10ec2ac4-6b8d-4cc6-fc13-800833aceb42"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed images shape: (7023, 299, 299)\n","Labels shape: (7023,)\n","\n","--- Split Dataset Info ---\n","Client 1 dataset size: 3011 images\n","Client 1 images shape: (3011, 299, 299)\n","Client 1 labels shape: (3011,)\n","Client 1 label distribution: (array([0, 1, 2, 3]), array([696, 729, 855, 731]))\n","Client 2 dataset size: 1806 images\n","Client 2 images shape: (1806, 299, 299)\n","Client 2 labels shape: (1806,)\n","Client 2 label distribution: (array([0, 1, 2, 3]), array([415, 401, 524, 466]))\n","Client 3 dataset size: 1206 images\n","Client 3 images shape: (1206, 299, 299)\n","Client 3 labels shape: (1206,)\n","Client 3 label distribution: (array([0, 1, 2, 3]), array([279, 281, 336, 310]))\n","\n","Test dataset size: 1000 images\n","Test images shape: (1000, 299, 299)\n","Test labels shape: (1000,)\n"]}]},{"cell_type":"markdown","source":["## Pickle save data to workspace\n","\n","Please adjust the ```base_save_dir``` below according to your folder hierarchy."],"metadata":{"id":"e5bv4EnU-1Wk"}},{"cell_type":"code","source":["import os\n","import pickle\n","\n","def save_data_to_pickle(data, filename, directory):\n","  \"\"\"Saves data to a pickle file in the specified directory.\"\"\"\n","  os.makedirs(directory, exist_ok=True) # Create directory if it doesn't exist\n","  filepath = os.path.join(directory, filename)\n","  try:\n","    with open(filepath, 'wb') as f:\n","      pickle.dump(data, f, protocol=4)\n","    print(f\"Successfully saved data to: {filepath}\")\n","  except Exception as e:\n","    print(f\"Error saving data to {filepath}: {e}\")\n","\n","\n","# Define the base directory for saving\n","# base_save_dir = \"/clients_data/bench\" # Modify as needed\n","base_save_dir ='/content/drive/MyDrive/Spring 25/github_brainfl/data/bench'\n","\n","# Save client data\n","for i, (client_images, client_labels) in enumerate(client_data):\n","  client_idx = i + 1\n","  save_data_to_pickle(client_images, f\"data_client{client_idx}.pickle\", base_save_dir)\n","  save_data_to_pickle(client_labels, f\"labels_client{client_idx}.pickle\", base_save_dir)\n","\n","# Save test data\n","# If you prefer a different path for test data, uncomment and modify the line below\n","# test_save_dir = \"/modify/if/different/test/path/preferred\"\n","test_save_dir = base_save_dir # Use the same path as client data by default\n","\n","save_data_to_pickle(test_data[0], \"test_images.pickle\", test_save_dir)\n","save_data_to_pickle(test_data[1], \"test_labels.pickle\", test_save_dir)\n"],"metadata":{"id":"5T34f04nDxqg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749601796723,"user_tz":240,"elapsed":2,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}},"outputId":"e12b5050-1152-4e43-8dce-ad491372f0d3"},"execution_count":6,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Successfully saved data to: /content/drive/MyDrive/Spring 25/github_brainfl/data/bench/data_client1.pickle\n","Successfully saved data to: /content/drive/MyDrive/Spring 25/github_brainfl/data/bench/labels_client1.pickle\n","Successfully saved data to: /content/drive/MyDrive/Spring 25/github_brainfl/data/bench/data_client2.pickle\n","Successfully saved data to: /content/drive/MyDrive/Spring 25/github_brainfl/data/bench/labels_client2.pickle\n","Successfully saved data to: /content/drive/MyDrive/Spring 25/github_brainfl/data/bench/data_client3.pickle\n","Successfully saved data to: /content/drive/MyDrive/Spring 25/github_brainfl/data/bench/labels_client3.pickle\n","Successfully saved data to: /content/drive/MyDrive/Spring 25/github_brainfl/data/bench/test_images.pickle\n","Successfully saved data to: /content/drive/MyDrive/Spring 25/github_brainfl/data/bench/test_labels.pickle\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"I02bNS9aXOTd"},"execution_count":null,"outputs":[]}]}