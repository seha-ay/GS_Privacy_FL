{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPDuKOZ9IF7v6VVrEzIiQBq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## README\n","\n","This notebook applies the Gerchberg‚ÄìSaxton (GS) algorithm to transform data into a more secure representation for downstream AI models, particularly to mitigate vulnerabilities to post-training attacks. Before proceeding, please ensure you have run the Load_and_Preprocess_Data.ipynb notebook and saved the generated client data to your working directory, as this is a required input for the transformations performed here.\n","\n","## ‚ö†Ô∏è GPU Acceleration with CUDA Compatibility Required\n","This notebook requires execution in a GPU-enabled environment with the cupy-cuda library correctly installed and matched to your system‚Äôs CUDA version.\n","\n","CPU execution is not supported due to the high computational demands of the Gerchberg‚ÄìSaxton (GS) transformations, particularly for the dataset used in this notebook.\n","\n","Before running, please ensure:\n","\n","- Your system has an NVIDIA GPU with CUDA support\n","- You have installed the appropriate cupy-cuda version for your CUDA runtime\n","\n","You can verify compatibility and install the correct package using the official CuPy guide:\n","\n","üëâ [CuPy Installation Guide with CUDA Compatibility](https://https://docs.cupy.dev/en/stable/install.html#installing-cupy)\n","\n","If GPU acceleration is unavailable on your local machine, we recommend using Google Colab, where this notebook is fully tested and compatible.\n","\n","## ‚úÖ Recommended Google Colab Setup\n","\n","  - Runtime Type: Python 3\n","  - Hardware Accelerator: T4 GPU (standard/free tier)\n","\n","\n","\n","### üìù Note\n","\n","A CPU-compatible version of the GS transformation is provided in the final code cell of the notebook. However, it is included for completeness only and is not recommended due to significant performance limitations."],"metadata":{"id":"b9ULiX7hMvpl"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jHBweCsJIar_","executionInfo":{"status":"ok","timestamp":1749602327170,"user_tz":240,"elapsed":3235,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}},"outputId":"50d63743-0dc1-4243-9533-b6254607e862"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## Imports and Functions"],"metadata":{"id":"H9D8kSm-ONUp"}},{"cell_type":"markdown","source":["If you are in the Google Colab with above setups, no modification needed in this code block, simply run all below. Otherwise, make sure you have the compatible cupy_cuda library with your CUDA environment installed to your kernel."],"metadata":{"id":"C-64oPXDOzIP"}},{"cell_type":"markdown","source":["If you are using Google Colab with the setup specified above, no modifications are needed‚Äîyou may simply run the code blocks below as-is.\n","\n","If you are running this notebook locally or in a different environment, ensure that your system has the cupy-cuda library installed and properly configured to match your CUDA version.\n","\n","Refer to the official CuPy installation guide for CUDA compatibility details:\n","\n","üëâ [CuPy Installation with CUDA Compatibility Matrix](https://https://docs.cupy.dev/en/stable/install.html#installing-cupy)\n","\n","Failure to configure this correctly may result in runtime errors or significant slowdowns during GPU-dependent operations."],"metadata":{"id":"A-MQsJVoPgop"}},{"cell_type":"code","source":["import numpy as np\n","import cupy as cp\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import pickle\n","import random\n","import math\n","import gc\n","from collections import Counter\n","import sys\n","import time\n","# from datetime import datetime\n","# import scipy\n","# from scipy.stats import entropy\n","# # import scipy.sparse as sp\n","# from scipy.sparse import issparse\n","\n","# from sklearn.preprocessing import StandardScaler\n","# from sklearn.cluster import KMeans\n","# from sklearn.decomposition import PCA\n","# from sklearn.manifold import TSNE\n","\n","import scipy.linalg\n","from scipy.linalg import dft\n","import seaborn as sns\n","import os"],"metadata":{"id":"76Awu0VSOtp5","executionInfo":{"status":"ok","timestamp":1749602329633,"user_tz":240,"elapsed":2467,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#@title GS\n","import cupy as cp\n","import scipy.linalg\n","from scipy.linalg import dft\n","\n","def dft_matrix(n):\n","    m = dft(n, scale='sqrtn')\n","    return m\n","\n","def imaginer_cp(t):\n","    return cp.exp(1j * t)\n","\n","def gs3D_GPU(data, iter, maskP=0):\n","    data = cp.array(data)\n","\n","    FF1 = cp.array(dft_matrix(data.shape[1]))\n","    FF2 = cp.array(dft_matrix(data.shape[2]))\n","    invFF1 = cp.linalg.inv(FF1)\n","    invFF2 = cp.linalg.inv(FF2)\n","    FF_tensor1 = cp.tile(FF1,(len(data),1,1))\n","    invFF_tensor1 = cp.tile(invFF1,(len(data),1,1))\n","    FF_tensor2 = cp.tile(FF2,(len(data),1,1))\n","    invFF_tensor2 = cp.tile(invFF2,(len(data),1,1))\n","\n","\n","    random_matrix = cp.random.uniform(low=0, high=2*cp.pi, size=(data.shape))\n","    vfunc = cp.vectorize(imaginer_cp)\n","    random_matrix_2 = vfunc(random_matrix)\n","\n","    for i in range(iter):\n","        mask = cp.random.choice((0,1), (data.shape), p = [maskP, 1-maskP])\n","        transformed = FF_tensor1@(data * random_matrix_2)@FF_tensor2\n","        mag_transformed = transformed/cp.abs(transformed)\n","        back_transformed = invFF_tensor1@(mag_transformed*mask)@invFF_tensor2\n","\n","        angles = cp.angle(back_transformed)\n","        random_matrix_2 = vfunc(angles)\n","\n","    ans = cp.abs(back_transformed)\n","    return ans.get()\n","\n","def GS_batch_image(data, batch_size, ite, maskP=0):\n","    '''\n","    This function divides data into batches to iterate within the GS,\n","    ensuring efficient RAM and GPU usage. Handles cases where the last batch\n","    contains fewer samples than the batch size by processing it separately.\n","    '''\n","    # Create an empty array to hold the data\n","    gs_array = np.empty((0, data.shape[1], data.shape[2]))\n","\n","    # Calculate the total number of full batches\n","    n_batch = len(data) // batch_size\n","\n","    # Batch iteration starts here\n","    for i in range(0, n_batch):\n","        # Process a full batch\n","        gs_batch = gs3D_GPU(data[i * batch_size:(i + 1) * batch_size], ite, maskP=maskP)\n","        gs_array = np.append(gs_array, gs_batch, axis=0)\n","        sys.stdout.write(f\"\\rBatch {i + 1} of {n_batch} (full batch) completed...\")\n","        sys.stdout.flush()\n","        time.sleep(0.001)\n","        del gs_batch\n","        gc.collect()\n","\n","    # Handle the remaining data as a smaller batch\n","    if len(data) % batch_size != 0:\n","        remaining_data = data[n_batch * batch_size:]\n","        gs_batch = gs3D_GPU(remaining_data, ite, maskP=maskP)\n","        gs_array = np.append(gs_array, gs_batch, axis=0)\n","        sys.stdout.write(f\"\\nRemaining data batch completed (size: {len(remaining_data)})...\")\n","        sys.stdout.flush()\n","        time.sleep(0.001)\n","        del gs_batch\n","        gc.collect()\n","\n","    return gs_array\n"],"metadata":{"cellView":"form","id":"DvrOQiHJOthV","executionInfo":{"status":"ok","timestamp":1749602329665,"user_tz":240,"elapsed":27,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Load and Transform Client Data\n","### üì• Loading Data\n","Update the base_load_path variable to match the directory where you saved the client data during execution of the Load_and_Preprocess_Data.ipynb notebook.\n","\n","    Important: This path must correctly reference the preprocessed client data\n","    directory. Failure to do so will result in downstream errors during data\n","    loading.\n","\n","Ensure that the specified path is valid and accessible within your current runtime environment.\n","\n","### üîÑ Transforming Data\n","Next, specify the base_save_path, which determines where the Gerchberg‚ÄìSaxton (GS) transformed images will be saved.\n","\n","For reproducibility and time-efficiency, this notebook applies the GS transformation using 20% masking, which was identified as the most effective configuration in our manuscript findings ([insert link here]).\n","\n","    You are encouraged to experiment with different masking levels by modifying\n","    the ```masking_percentage``` parameter below.\n","\n","Be aware that increasing the masking level may affect both performance and transformation time."],"metadata":{"id":"BkYQ8mnQOr4Z"}},{"cell_type":"code","source":["# import time\n","# import pickle\n","# import gc\n","\n","# base_load_path = '/content/drive/MyDrive/Spring 25/github_brainfl/data/bench'\n","# base_save_path = '/content/drive/MyDrive/Spring 25/github_brainfl/data/gs'\n","\n","# masking_percentage = 20  # Modify as needed (Default = 20 for 20%)\n","# maskP = masking_percentage / 100  # DO NOT MODIFY PLEASE!!!!\n","\n","# for client in range(3):\n","#     start_time = time.time()\n","#     print(f\"\\n=== [Client {client+1}] Start Processing ===\")\n","\n","#     # Load data\n","#     print(f\"[Client {client+1}] Loading data...\")\n","#     with open(f'{base_load_path}/data_client{client+1}.pickle', 'rb') as f:\n","#         data_bench = pickle.load(f)\n","\n","#     # Apply GS Transformation\n","#     print(f\"[Client {client+1}] Applying GS transformation (masking: {masking_percentage}%)...\")\n","#     data_gs = GS_batch_image(data_bench, batch_size=400, ite=50, maskP=maskP)\n","\n","#     # Free memory\n","#     del data_bench\n","#     gc.collect()\n","\n","#     # Save transformed data\n","#     print(f\"[Client {client+1}] Saving transformed data...\")\n","#     with open(f'{base_save_path}/data_client{client+1}_gs.pickle', 'wb') as f:\n","#         pickle.dump(data_gs, f)\n","\n","#     print(f\"[Client {client+1}] ‚úÖ Done in {time.time() - start_time:.2f} seconds\")\n","\n","#     #Free memory\n","#     del data_gs\n","#     gc.collect()\n","\n","\n","# start_time = time.time()\n","\n","# print(f\"Loading Test data...\")\n","# data_bench = pickle.load(open(f'{base_load_path}/test_images.pickle','rb'))\n","\n","# print(f\"Applying GS transformation to Test Data (masking: {masking_percentage}%)...\")\n","# data_gs = GS_batch_image(data_bench, batch_size=400, ite=50, maskP=maskP)\n","\n","# with open(f'{base_save_path}/test_images_gs.pickle', 'wb') as f:\n","#     pickle.dump(data_gs, f)\n","\n","# print(f\"Test ‚úÖ Done in {time.time() - start_time:.2f} seconds\")"],"metadata":{"id":"eUqScMrAWc3j","executionInfo":{"status":"ok","timestamp":1749602329711,"user_tz":240,"elapsed":29,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import time\n","import pickle\n","import gc\n","import random\n","import matplotlib.pyplot as plt\n","\n","base_load_path = '/content/drive/MyDrive/Spring 25/github_brainfl/data/bench'\n","base_save_path = '/content/drive/MyDrive/Spring 25/github_brainfl/data/gs'\n","\n","masking_percentage = 20  # Modify as needed (Default = 20 for 20%)\n","maskP = masking_percentage / 100  # DO NOT MODIFY PLEASE!!!!\n","\n","for client in range(3):\n","    start_time = time.time()\n","    print(f\"\\n=== [Client {client+1}] Start Processing ===\")\n","\n","    # Load data\n","    print(f\"[Client {client+1}] Loading data...\")\n","    with open(f'{base_load_path}/data_client{client+1}.pickle', 'rb') as f:\n","        data_bench = pickle.load(f)\n","\n","    # Apply GS Transformation\n","    print(f\"[Client {client+1}] Applying GS transformation (masking: {masking_percentage}%)...\")\n","    data_gs = GS_batch_image(data_bench, batch_size=400, ite=50, maskP=maskP)\n","\n","    # === Visualize 4 random samples ===\n","    print(f\"[Client {client+1}] Visualizing sample transformations...\")\n","    sample_indices = random.sample(range(len(data_bench)), 4)\n","    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n","    fig.suptitle(f\"Client {client+1}: Original (Top) vs GS Transformed (Bottom)\", fontsize=14)\n","\n","    for i, idx in enumerate(sample_indices):\n","        axes[0, i].imshow(data_bench[idx], cmap='gray')\n","        axes[0, i].axis('off')\n","        axes[0, i].set_title(f\"Original {idx}\")\n","\n","        axes[1, i].imshow(data_gs[idx], cmap='gray')\n","        axes[1, i].axis('off')\n","        axes[1, i].set_title(f\"GS {idx}\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Save transformed data\n","    print(f\"[Client {client+1}] Saving transformed data...\")\n","    with open(f'{base_save_path}/data_client{client+1}_gs{masking_percentage}p.pickle', 'wb') as f:\n","        pickle.dump(data_gs, f)\n","\n","    print(f\"[Client {client+1}] ‚úÖ Done in {time.time() - start_time:.2f} seconds\")\n","\n","    # Free memory\n","    del data_bench\n","    del data_gs\n","    gc.collect()\n","\n","\n","# === TEST DATA PROCESSING ===\n","start_time = time.time()\n","print(f\"\\n=== [Test Set] Start Processing ===\")\n","\n","print(f\"Loading Test data...\")\n","with open(f'{base_load_path}/test_images.pickle', 'rb') as f:\n","    data_bench = pickle.load(f)\n","\n","print(f\"Applying GS transformation to Test Data (masking: {masking_percentage}%)...\")\n","data_gs = GS_batch_image(data_bench, batch_size=400, ite=50, maskP=maskP)\n","\n","print(\"Saving transformed test data...\")\n","with open(f'{base_save_path}/test_images_gs{masking_percentage}p.pickle', 'wb') as f:\n","    pickle.dump(data_gs, f)\n","\n","print(f\"[Test Set] ‚úÖ Done in {time.time() - start_time:.2f} seconds\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1kaBfu7IbiwV-uqd8kw-2aAaPxPmtCGBV"},"id":"KnckxcSzWk6i","executionInfo":{"status":"ok","timestamp":1749604842396,"user_tz":240,"elapsed":1748784,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}},"outputId":"3164c130-ee59-4b31-cc23-bd00ea271dd2"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"xE-Om8OgeIqj"},"execution_count":null,"outputs":[]}]}