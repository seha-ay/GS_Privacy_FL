{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["LD_NgH2SmR-b","1zpqHct5q10E"],"gpuType":"T4","authorship_tag":"ABX9TyOE97+Z6DN82hQvN8RK5JX/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["##README\n","\n","In this notebook, we will be testing our pre-trained model performances with the bench and GS transformed versions of the data and compare the results in terms of accuracy loss.\n","\n","For the sake of this notebook we will be using the pretrained models under the pretrianed_model repository. If you would prefer to re-trained the model with the transformed data, please contact with the corresponding author for the FL simulation framework."],"metadata":{"id":"j1AA088lmSEu"}},{"cell_type":"markdown","source":[],"metadata":{"id":"kTN7A0sdmSBB"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBgftcsZrEKC","executionInfo":{"status":"ok","timestamp":1749660363652,"user_tz":240,"elapsed":18724,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}},"outputId":"9de53248-5318-450f-9303-e5f9f01bdc85"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Imports and Functions"],"metadata":{"id":"-HtahAGvtYth"}},{"cell_type":"code","source":["import os\n","import torch\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","from tqdm import tqdm\n","import torch.nn as nn\n","\n","# === CONFIGURATION ===\n","SAVE_PATH = \"/content/drive/MyDrive/Spring 25/github_brainfl/results/accuracy\"  # <-- Replace with your save directory\n","TEST_IMAGE_PATH = \"/content/drive/MyDrive/Spring 25/github_brainfl/data/bench/test_images.pickle\"  # <-- Replace\n","TEST_LABEL_PATH = \"/content/drive/MyDrive/Spring 25/github_brainfl/data/bench/test_labels.pickle\"  # <-- Replace\n","\n","VARIANT_CONFIGS = {\n","    \"bench\": {\n","        \"global_model_path\": \"/content/drive/MyDrive/Spring 25/github_brainfl/pretrained_models/global_model.pth\",# <-- Replace\n","        \"client_model_paths\": {\n","            \"client_1\": \"/content/drive/MyDrive/Spring 25/github_brainfl/pretrained_models/client_0_model.pth\",# <-- Replace\n","            \"client_2\": \"/content/drive/MyDrive/Spring 25/github_brainfl/pretrained_models/client_1_model.pth\",# <-- Replace\n","            \"client_3\": \"/content/drive/MyDrive/Spring 25/github_brainfl/pretrained_models/client_2_model.pth\",# <-- Replace\n","        },\n","        \"test_image_path\": \"/content/drive/MyDrive/Spring 25/github_brainfl/data/bench/test_images.pickle\",# <-- Replace\n","        \"test_label_path\": \"/content/drive/MyDrive/Spring 25/github_brainfl/data/bench/test_labels.pickle\"# <-- Replace\n","    },\n","    \"mask_20\": {\n","        \"global_model_path\": \"/content/drive/MyDrive/Spring 25/github_brainfl/pretrained_models/global_model_gs20p.pth\",# <-- Replace\n","        \"client_model_paths\": {\n","            \"client_1\": \"/content/drive/MyDrive/Spring 25/github_brainfl/pretrained_models/client_0_model_gs20p.pth\",# <-- Replace\n","            \"client_2\": \"/content/drive/MyDrive/Spring 25/github_brainfl/pretrained_models/client_1_model_gs20p.pth\",# <-- Replace\n","            \"client_3\": \"/content/drive/MyDrive/Spring 25/github_brainfl/pretrained_models/client_2_model_gs20p.pth\",# <-- Replace\n","        },\n","        \"test_image_path\": \"/content/drive/MyDrive/Spring 25/github_brainfl/data/gs/test_images_gs20p.pickle\",# <-- Replace\n","        \"test_label_path\": \"/content/drive/MyDrive/Spring 25/github_brainfl/data/bench/test_labels.pickle\"# <-- Replace\n","    }\n","    ## You can add more variants here to broaden your model evaluations\n","    ## To Do, you will need to GS transform the original data with desired settings, train a model,\n","    ## and save the trained model paths to your directory\n","}\n","\n","# === MODEL ===\n","class BrainMRIClassifier(torch.nn.Module):\n","    def __init__(self):\n","        super(BrainMRIClassifier, self).__init__()\n","        self.features = torch.nn.Sequential(\n","            torch.nn.Conv2d(1, 32, kernel_size=3, padding=1), torch.nn.ReLU(), torch.nn.MaxPool2d(2), torch.nn.BatchNorm2d(32),\n","            torch.nn.Conv2d(32, 64, kernel_size=3, padding=1), torch.nn.ReLU(), torch.nn.MaxPool2d(2), torch.nn.BatchNorm2d(64),\n","            torch.nn.Conv2d(64, 128, kernel_size=3, padding=1), torch.nn.ReLU(), torch.nn.MaxPool2d(2), torch.nn.BatchNorm2d(128),\n","            torch.nn.Conv2d(128, 256, kernel_size=3, padding=1), torch.nn.ReLU(), torch.nn.MaxPool2d(2), torch.nn.BatchNorm2d(256),\n","            torch.nn.Conv2d(256, 256, kernel_size=3, padding=1), torch.nn.ReLU(), torch.nn.MaxPool2d(2), torch.nn.BatchNorm2d(256),\n","        )\n","        self.flat_features = 256 * 9 * 9\n","        self.classifier = torch.nn.Sequential(\n","            torch.nn.Flatten(), torch.nn.Dropout(0.5),\n","            torch.nn.Linear(self.flat_features, 512), torch.nn.ReLU(), torch.nn.Dropout(0.5),\n","            torch.nn.Linear(512, 256), torch.nn.ReLU(), torch.nn.Dropout(0.5),\n","            torch.nn.Linear(256, 4)\n","        )\n","    def forward(self, x):\n","        return self.classifier(self.features(x))\n","\n","# === UTILS ===\n","def load_data(images_path, labels_path):\n","    with open(images_path, 'rb') as f: images = pickle.load(f)\n","    with open(labels_path, 'rb') as f: labels = pickle.load(f)\n","    images = torch.tensor(np.array(images)).float()\n","    if images.ndim == 3: images = images.unsqueeze(1)\n","    labels = torch.tensor(np.array(labels)).long()\n","    return torch.utils.data.TensorDataset(images, labels)\n","\n","def compute_metrics(model, loader, device):\n","    model.eval()\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(device), y.to(device)\n","            out = model(x)\n","            _, preds = torch.max(out, 1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(y.cpu().numpy())\n","    acc = accuracy_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n","    cm = confusion_matrix(all_labels, all_preds)\n","    return {\"accuracy\": acc, \"f1_score\": f1, \"confusion_matrix\": cm}\n","\n","def create_heatmap(df, metric_prefix, output_file, title):\n","    import matplotlib.colors as mcolors\n","    import matplotlib.patches as patches\n","\n","    rows = df[\"Variant\"]\n","\n","    # Construct correct column names\n","    if metric_prefix in [\"F1\", \"Acc\"]:\n","        cols = [f\"{k}_{metric_prefix}\" for k in [\"Global\", \"Client 1\", \"Client 2\", \"Client 3\"]]\n","    else:\n","        raise ValueError(f\"Unsupported metric_prefix: {metric_prefix}\")\n","\n","    data = df[cols].values\n","    normed_data = np.zeros_like(data)\n","\n","    # Normalize per column\n","    for j in range(data.shape[1]):\n","        col = data[:, j]\n","        col_min, col_max = col.min(), col.max()\n","        if col_max > col_min:\n","            normed_data[:, j] = (col - col_min) / (col_max - col_min)\n","        else:\n","            normed_data[:, j] = 0.5  # neutral\n","\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","\n","    cmap = plt.get_cmap(\"RdYlGn\")\n","    im = ax.imshow(normed_data, cmap=cmap)\n","\n","    # Set ticks and labels\n","    ax.set_xticks(np.arange(len(cols)))\n","    ax.set_yticks(np.arange(len(rows)))\n","    ax.set_xticklabels([\"Global\", \"Client 1\", \"Client 2\", \"Client 3\"])\n","    ax.set_yticklabels(rows)\n","\n","    # Draw black grid lines\n","    for i in range(len(rows) + 1):\n","        ax.axhline(i - 0.5, color='black', linewidth=1)\n","    for j in range(len(cols) + 1):\n","        ax.axvline(j - 0.5, color='black', linewidth=1)\n","\n","    # Add cell text\n","    for i in range(len(rows)):\n","        for j in range(len(cols)):\n","            ax.text(j, i, f\"{data[i, j]:.2f}\", ha=\"center\", va=\"center\", color=\"black\", fontsize=11)\n","\n","    ax.set_title(title, fontsize=16, pad=20)\n","    plt.tight_layout()\n","    plt.savefig(output_file, dpi=300)\n","    plt.close()\n","\n","\n","# === MAIN EXECUTION ===\n","def evaluate_and_plot():\n","    os.makedirs(SAVE_PATH, exist_ok=True)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    rows = []\n","\n","    print(\"\\nüîç Starting model evaluations...\\n\")\n","    for variant in tqdm(VARIANT_CONFIGS.keys(), desc=\"Evaluating variants\"):\n","        paths = VARIANT_CONFIGS[variant]\n","        row = {\"Variant\": variant}\n","\n","        tqdm.write(f\"üìÅ Loading test data for variant: {variant}\")\n","        test_dataset = load_data(paths[\"test_image_path\"], paths[\"test_label_path\"])\n","        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","        tqdm.write(f\"üîÑ Evaluating global model for {variant}\")\n","        model = BrainMRIClassifier().to(device)\n","        model.load_state_dict(torch.load(paths[\"global_model_path\"], map_location=device))\n","        metrics = compute_metrics(model, test_loader, device)\n","        row[\"Global_F1\"] = metrics[\"f1_score\"]\n","        row[\"Global_Acc\"] = metrics[\"accuracy\"]\n","\n","        for i in range(1, 4):\n","            key = f\"client_{i}\"\n","            tqdm.write(f\"üîÑ Evaluating {variant} - Client {i}\")\n","            model = BrainMRIClassifier().to(device)\n","            model.load_state_dict(torch.load(paths[\"client_model_paths\"][key], map_location=device))\n","            metrics = compute_metrics(model, test_loader, device)\n","            row[f\"Client {i}_F1\"] = metrics[\"f1_score\"]\n","            row[f\"Client {i}_Acc\"] = metrics[\"accuracy\"]\n","\n","        rows.append(row)\n","\n","    df = pd.DataFrame(rows)\n","    df.to_csv(os.path.join(SAVE_PATH, \"multi_variant_metrics.csv\"), index=False)\n","    print(df.head())\n","\n","    tqdm.write(\"üìä Generating heatmaps...\")\n","    create_heatmap(df, \"F1\", os.path.join(SAVE_PATH, \"f1_score_comparison.png\"), \"F1 Score Comparison\")\n","    create_heatmap(df, \"Acc\", os.path.join(SAVE_PATH, \"accuracy_comparison.png\"), \"Accuracy Score Comparison\")\n","\n","    print(\"\\n‚úÖ All evaluations and plots successfully saved to:\", SAVE_PATH)"],"metadata":{"id":"a3HPVoBWtYag","executionInfo":{"status":"ok","timestamp":1749660371112,"user_tz":240,"elapsed":5962,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Run\n","if __name__ == \"__main__\":\n","    evaluate_and_plot()"],"metadata":{"id":"HGb4fQ7suOMW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749660429392,"user_tz":240,"elapsed":58110,"user":{"displayName":"Seha Ay","userId":"11359939364231438053"}},"outputId":"21bf1c55-4f47-4070-edbe-ae707d47a58c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîç Starting model evaluations...\n","\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating variants:   0%|          | 0/2 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["üìÅ Loading test data for variant: bench\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating variants:   0%|          | 0/2 [00:05<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["üîÑ Evaluating global model for bench\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating variants:   0%|          | 0/2 [00:10<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["üîÑ Evaluating bench - Client 1\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating variants:   0%|          | 0/2 [00:14<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["üîÑ Evaluating bench - Client 2\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating variants:   0%|          | 0/2 [00:18<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["üîÑ Evaluating bench - Client 3\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating variants:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:23<00:23, 23.19s/it]"]},{"output_type":"stream","name":"stdout","text":["üìÅ Loading test data for variant: mask_20\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating variants:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:34<00:23, 23.19s/it]"]},{"output_type":"stream","name":"stdout","text":["üîÑ Evaluating global model for mask_20\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating variants:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:38<00:23, 23.19s/it]"]},{"output_type":"stream","name":"stdout","text":["üîÑ Evaluating mask_20 - Client 1\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating variants:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:43<00:23, 23.19s/it]"]},{"output_type":"stream","name":"stdout","text":["üîÑ Evaluating mask_20 - Client 2\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating variants:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:48<00:23, 23.19s/it]"]},{"output_type":"stream","name":"stdout","text":["üîÑ Evaluating mask_20 - Client 3\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating variants: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:52<00:00, 26.31s/it]\n"]},{"output_type":"stream","name":"stdout","text":["   Variant  Global_F1  Global_Acc  Client 1_F1  Client 1_Acc  Client 2_F1  \\\n","0    bench   0.945754       0.948     0.897482         0.908     0.954442   \n","1  mask_20   0.969170       0.971     0.919536         0.926     0.957561   \n","\n","   Client 2_Acc  Client 3_F1  Client 3_Acc  \n","0         0.957     0.948827         0.951  \n","1         0.959     0.944202         0.948  \n","üìä Generating heatmaps...\n","\n","‚úÖ All evaluations and plots successfully saved to: /content/drive/MyDrive/Spring 25/github_brainfl/results/accuracy\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"619gs0cF3TY1"},"execution_count":null,"outputs":[]}]}